# LiteLLM proxy configuration for Cloud Run
# Environment variables expected:
# - OPENAI_API_KEY: provider key
# - PROXY_GATEWAY_TOKEN: bearer token clients must present
# - PROXY_MASTER_KEY: optional master key for admin/debug

model_list:
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: ${OPENAI_API_KEY}
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: ${OPENAI_API_KEY}

general_settings:
  master_key: ${PROXY_MASTER_KEY}

litellm_settings:
  success_callback: ["callbacks.logging.log_event", "callbacks.db.log_event"]
  failure_callback: ["callbacks.logging.log_event", "callbacks.db.log_event"]

proxy:
  port: ${PORT:-8080}
  host: 0.0.0.0
  log_level: INFO
  enable_cors: false
  timeout: 120
  auth:
    type: bearer
    tokens:
      - ${PROXY_GATEWAY_TOKEN}

